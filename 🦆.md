# Debug docs
used by me to jot down notes to remember. Not very entertaining and does not help with the project for anyone other then me or possible contributors

## Ratelimits
using **POST** to a channel returns headers with x-ratelimit\* values, GET requests to a channel seems not to.
**HOWEVER** as per the [Global Rate Limit](https://discord.com/developers/docs/topics/rate-limits#global-rate-limit) 50 requests per second is the max amount of requests you are allowed to make to the API regardless of path. I am guesstimating that this global rate limit is what *borked* the bot trying to init after my internet shortage as it made 200+ GET requests probably within that timeframe as I did not account for the global rate limit. This is something I need to take into account

### Solving this
I already know how many queries minimal need to be done at init, as I know how many threads there are in the database. Now, each of these threads could also need un-archiving which makes the range t<sub>n</sub>-2t<sub>n</sub> as theoretically all threads could be archived albeit unlikely. 

What I think is easier to implement in regards to global rate limits is to do all the GET requests first as no guess-work needs to be done on how many requests needs doing. All threads that were indeed archived will then be added to a queue and handled after all the GET requests are done

my solve is slow and lazy but might just work